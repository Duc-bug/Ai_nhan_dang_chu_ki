import cv2
import numpy as np
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

class SignatureProcessor:
    def __init__(self, target_size=(128, 128)):
        self.target_size = target_size
        self.scaler = StandardScaler()
    
    def preprocess_image(self, image_input):
        """
        X·ª≠ l√Ω ·∫£nh ch·ªØ k√Ω: chuy·ªÉn sang grayscale, resize, normalize
        """
        try:
            # X·ª≠ l√Ω input - c√≥ th·ªÉ l√† ƒë∆∞·ªùng d·∫´n file ho·∫∑c numpy array
            if isinstance(image_input, str):
                # ƒê·ªçc t·ª´ file
                image = cv2.imread(image_input)
                if image is None:
                    raise ValueError(f"Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh t·ª´ {image_input}")
            elif hasattr(image_input, 'read'):
                # File object t·ª´ Streamlit
                import io
                from PIL import Image
                pil_image = Image.open(image_input)
                image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)
            else:
                # Numpy array
                image = image_input.copy()
            
            # ƒê·∫£m b·∫£o ·∫£nh kh√¥ng None
            if image is None:
                raise ValueError("·∫¢nh ƒë·∫ßu v√†o kh√¥ng h·ª£p l·ªá")
            
            # Chuy·ªÉn sang grayscale
            if len(image.shape) == 3:
                if image.shape[2] == 4:  # RGBA
                    gray = cv2.cvtColor(image, cv2.COLOR_BGRA2GRAY)
                elif image.shape[2] == 3:  # RGB/BGR
                    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
                else:
                    gray = image[:, :, 0]  # L·∫•y channel ƒë·∫ßu ti√™n
            else:
                gray = image.copy()
            
            # ƒê·∫£m b·∫£o ·∫£nh c√≥ k√≠ch th∆∞·ªõc h·ª£p l·ªá
            if gray.shape[0] == 0 or gray.shape[1] == 0:
                raise ValueError("·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá")
            
            # C·∫£i thi·ªán contrast
            gray = cv2.equalizeHist(gray)
            
            # √Åp d·ª•ng threshold ƒë·ªÉ t√°ch n·ªÅn (adaptive threshold t·ªët h∆°n)
            binary = cv2.adaptiveThreshold(
                gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                cv2.THRESH_BINARY_INV, 11, 2
            )
            
            # T√¨m contours ƒë·ªÉ crop ·∫£nh
            contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            if contours:
                # L·ªçc contours qu√° nh·ªè
                filtered_contours = [c for c in contours if cv2.contourArea(c) > 50]
                
                if filtered_contours:
                    # T√¨m bounding box c·ªßa t·∫•t c·∫£ contours
                    all_contours = np.vstack(filtered_contours)
                    x, y, w, h = cv2.boundingRect(all_contours)
                    
                    # Crop ·∫£nh v·ªõi padding
                    padding = 20
                    x = max(0, x - padding)
                    y = max(0, y - padding)
                    x2 = min(gray.shape[1], x + w + 2 * padding)
                    y2 = min(gray.shape[0], y + h + 2 * padding)
                    
                    cropped = gray[y:y2, x:x2]
                else:
                    cropped = gray
            else:
                cropped = gray
            
            # ƒê·∫£m b·∫£o cropped c√≥ k√≠ch th∆∞·ªõc h·ª£p l√Ω
            if cropped.shape[0] < 10 or cropped.shape[1] < 10:
                cropped = gray
            
            # Resize v·ªÅ k√≠ch th∆∞·ªõc chu·∫©n
            resized = cv2.resize(cropped, self.target_size, interpolation=cv2.INTER_AREA)
            
            # Normalize v·ªÅ [0, 1]
            normalized = resized.astype(np.float32) / 255.0
            
            return normalized
            
        except Exception as e:
            print(f"L·ªói x·ª≠ l√Ω ·∫£nh: {str(e)}")
            # Tr·∫£ v·ªÅ ·∫£nh ƒëen nh∆∞ fallback
            return np.zeros(self.target_size, dtype=np.float32)
    
    def extract_features(self, image):
        """
        Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng t·ª´ ·∫£nh ch·ªØ k√Ω - FIXED VERSION
        """
        try:
            print(f"üîç B·∫Øt ƒë·∫ßu tr√≠ch xu·∫•t features t·ª´ ·∫£nh shape: {image.shape}")
            
            # Validate input
            if image is None:
                raise ValueError("·∫¢nh ƒë·∫ßu v√†o l√† None")
            
            if len(image.shape) != 2:
                raise ValueError(f"·∫¢nh ph·∫£i l√† grayscale 2D, nh·∫≠n ƒë∆∞·ª£c shape: {image.shape}")
            
            # Ki·ªÉm tra k√≠ch th∆∞·ªõc ·∫£nh
            if image.shape != self.target_size:
                print(f"‚ö†Ô∏è ·∫¢nh kh√¥ng ƒë√∫ng k√≠ch th∆∞·ªõc: {image.shape}, resize v·ªÅ {self.target_size}")
                image = cv2.resize(image, self.target_size, interpolation=cv2.INTER_AREA)
            
            # ƒê·∫£m b·∫£o ·∫£nh ƒë√∫ng ƒë·ªãnh d·∫°ng
            if image.dtype != np.float32:
                image = image.astype(np.float32)
            
            # Chuy·ªÉn v·ªÅ [0,255] cho vi·ªác t√≠nh gradient
            if np.max(image) <= 1.0:
                image_255 = (image * 255).astype(np.uint8)
            else:
                image_255 = image.astype(np.uint8)
            
            print(f"üìä ·∫¢nh sau preprocessing: shape={image.shape}, dtype={image.dtype}, min={np.min(image):.3f}, max={np.max(image):.3f}")
            
            # 1. RAW PIXEL FEATURES (128x128 = 16,384 features)
            raw_pixels = image.flatten()
            print(f"‚úÖ Raw pixels: {len(raw_pixels)} features")
            
            # 2. GRADIENT FEATURES
            try:
                # T√≠nh gradient b·∫±ng Sobel
                grad_x = cv2.Sobel(image_255, cv2.CV_64F, 1, 0, ksize=3)
                grad_y = cv2.Sobel(image_255, cv2.CV_64F, 0, 1, ksize=3)
                
                # Magnitude v√† direction
                magnitude = np.sqrt(grad_x**2 + grad_y**2)
                angle = np.arctan2(grad_y, grad_x)
                
                print(f"‚úÖ Gradient: magnitude shape={magnitude.shape}, angle shape={angle.shape}")
                
                # Histogram c·ªßa magnitude (32 bins)
                mag_hist, _ = np.histogram(magnitude.flatten(), bins=32, range=(0, 300))  # TƒÉng range
                mag_hist = mag_hist.astype(np.float32)
                if np.sum(mag_hist) > 0:
                    mag_hist = mag_hist / np.sum(mag_hist)  # Normalize
                print(f"‚úÖ Magnitude histogram: {len(mag_hist)} bins, sum={np.sum(mag_hist):.3f}")
                
                # Histogram c·ªßa g√≥c (32 bins) 
                angle_hist, _ = np.histogram(angle.flatten(), bins=32, range=(-np.pi, np.pi))
                angle_hist = angle_hist.astype(np.float32)
                if np.sum(angle_hist) > 0:
                    angle_hist = angle_hist / np.sum(angle_hist)  # Normalize
                print(f"‚úÖ Angle histogram: {len(angle_hist)} bins, sum={np.sum(angle_hist):.3f}")
                
            except Exception as e:
                print(f"‚ö†Ô∏è L·ªói gradient features: {e}")
                mag_hist = np.zeros(32, dtype=np.float32)
                angle_hist = np.zeros(32, dtype=np.float32)
        
        # 3. STATISTICAL FEATURES (5 features)
        try:
            mean_val = float(np.mean(image))
            std_val = float(np.std(image))
            min_val = float(np.min(image))
            max_val = float(np.max(image))
            
            # T·ª∑ l·ªá pixel s√°ng (threshold = 0.5 cho normalized image)
            if np.max(image) <= 1.0:
                bright_ratio = float(np.sum(image > 0.5) / image.size)
            else:
                bright_ratio = float(np.sum(image > 127) / image.size)
            
            stats = np.array([mean_val, std_val, min_val, max_val, bright_ratio], dtype=np.float32)
            print(f"‚úÖ Statistical features: {stats}")
            
        except Exception as e:
            print(f"‚ö†Ô∏è L·ªói statistical features: {e}")
            stats = np.zeros(5, dtype=np.float32)
        
        # 4. K·∫æT H·ª¢P T·∫§T C·∫¢ FEATURES
        try:
            features = np.concatenate([
                raw_pixels,    # 16,384 features (128x128)
                mag_hist,      # 32 features  
                angle_hist,    # 32 features
                stats         # 5 features
            ])
            print(f"‚úÖ K·∫øt h·ª£p features: {len(features)} total")
            # Total: 16,384 + 32 + 32 + 5 = 16,453 features
            
        except Exception as e:
            print(f"‚ùå L·ªói k·∫øt h·ª£p features: {e}")
            expected_size = self.target_size[0] * self.target_size[1] + 32 + 32 + 5
            return np.zeros(expected_size, dtype=np.float32)
        
        # Validate output size
        expected_size = self.target_size[0] * self.target_size[1] + 32 + 32 + 5
        if len(features) != expected_size:
            print(f"‚ö†Ô∏è K√≠ch th∆∞·ªõc features kh√¥ng ƒë√∫ng: {len(features)}, mong ƒë·ª£i: {expected_size}")
            # Resize n·∫øu c·∫ßn
            if len(features) < expected_size:
                features = np.pad(features, (0, expected_size - len(features)), 'constant')
            else:
                features = features[:expected_size]
        
        # Validate output
        if np.any(np.isnan(features)) or np.any(np.isinf(features)):
            print("‚ö†Ô∏è Features ch·ª©a NaN ho·∫∑c Inf, ƒëang s·ª≠a...")
            features = np.nan_to_num(features, nan=0.0, posinf=1.0, neginf=0.0)
        
        print(f"‚úÖ Tr√≠ch xu·∫•t th√†nh c√¥ng {len(features)} features")
        return features.astype(np.float32)
        
    except Exception as e:
        print(f"‚ùå L·ªói tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng: {str(e)}")
        import traceback
        traceback.print_exc()
        # Tr·∫£ v·ªÅ vector zero v·ªõi k√≠ch th∆∞·ªõc ch√≠nh x√°c
        fallback_size = self.target_size[0] * self.target_size[1] + 32 + 32 + 5  # 16,453
        return np.zeros(fallback_size, dtype=np.float32)
    
    def calculate_similarity(self, features1, features2):
        """
        So s√°nh ƒë·ªô t∆∞∆°ng ƒë·ªìng - IMPROVED VERSION
        """
        try:
            # Validate inputs
            if features1 is None or features2 is None:
                print("‚ùå Features l√† None")
                return 0.0
            
            f1 = np.array(features1, dtype=np.float32).flatten()
            f2 = np.array(features2, dtype=np.float32).flatten()
            
            if len(f1) == 0 or len(f2) == 0:
                print("‚ùå Features r·ªóng")
                return 0.0
            
            if len(f1) != len(f2):
                print(f"‚ùå Features kh√°c chi·ªÅu: {len(f1)} vs {len(f2)}")
                return 0.0
            
            # Clean data
            f1 = np.nan_to_num(f1, nan=0.0, posinf=1.0, neginf=0.0)
            f2 = np.nan_to_num(f2, nan=0.0, posinf=1.0, neginf=0.0)
            
            # Method 1: Cosine Similarity
            dot_product = np.dot(f1, f2)
            norm1 = np.linalg.norm(f1)
            norm2 = np.linalg.norm(f2)
            
            if norm1 == 0 or norm2 == 0:
                cosine_sim = 0.0
            else:
                cosine_sim = dot_product / (norm1 * norm2)
                cosine_sim = max(0, min(1, cosine_sim))
            
            # Method 2: Euclidean Similarity v·ªõi standardization
            try:
                # Combine v√† standardize
                combined = np.vstack([f1.reshape(1, -1), f2.reshape(1, -1)])
                scaler = StandardScaler()
                scaled = scaler.fit_transform(combined)
                
                f1_scaled = scaled[0]
                f2_scaled = scaled[1]
                
                # Euclidean distance
                distance = np.linalg.norm(f1_scaled - f2_scaled)
                max_distance = np.sqrt(len(f1_scaled))
                
                euclidean_sim = 1 - (distance / max_distance)
                euclidean_sim = max(0, min(1, euclidean_sim))
                
            except Exception:
                euclidean_sim = cosine_sim
            
            # Weighted combination
            final_similarity = 0.6 * cosine_sim + 0.4 * euclidean_sim
            
            print(f"üîç Cosine: {cosine_sim:.4f}, Euclidean: {euclidean_sim:.4f}, Final: {final_similarity:.4f}")
            
            return float(final_similarity)
            
        except Exception as e:
            print(f"‚ùå L·ªói t√≠nh similarity: {str(e)}")
            return 0.0
    
    def compare_signatures(self, image1, image2):
        """
        So s√°nh 2 ·∫£nh ch·ªØ k√Ω ho√†n ch·ªânh
        """
        try:
            print("üîÑ B·∫Øt ƒë·∫ßu so s√°nh ch·ªØ k√Ω...")
            
            # Preprocess
            processed1 = self.preprocess_image(image1)
            processed2 = self.preprocess_image(image2)
            
            # Extract features
            features1 = self.extract_features(processed1)
            features2 = self.extract_features(processed2)
            
            # Calculate similarity
            similarity = self.calculate_similarity(features1, features2)
            
            print(f"‚úÖ Ho√†n th√†nh so s√°nh. Similarity: {similarity:.4f}")
            
            return {
                'similarity': similarity,
                'processed_image1': processed1,
                'processed_image2': processed2,
                'features1': features1,
                'features2': features2
            }
            
        except Exception as e:
            print(f"‚ùå L·ªói so s√°nh ch·ªØ k√Ω: {str(e)}")
            return {
                'similarity': 0.0,
                'processed_image1': np.zeros(self.target_size, dtype=np.float32),
                'processed_image2': np.zeros(self.target_size, dtype=np.float32), 
                'features1': np.zeros(16453, dtype=np.float32),
                'features2': np.zeros(16453, dtype=np.float32)
            }
    
    def visualize_signature(self, image, title="Ch·ªØ k√Ω"):
        """
        Hi·ªÉn th·ªã ·∫£nh ch·ªØ k√Ω
        """
        try:
            plt.figure(figsize=(8, 6))
            if len(image.shape) == 2:
                plt.imshow(image, cmap='gray')
            else:
                plt.imshow(image)
            plt.title(title)
            plt.axis('off')
            plt.show()
        except Exception as e:
            print(f"L·ªói hi·ªÉn th·ªã ·∫£nh: {str(e)}")



if __name__ == "__main__":
    test_processor()
